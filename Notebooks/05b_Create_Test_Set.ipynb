{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fccc2b",
   "metadata": {},
   "source": [
    "# <u>Drought Prediction</u>: Preprocessing - Resample [Mean, Max, Min], Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b7a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pandas, matplotlib.pyplot, and seaborn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce3204f",
   "metadata": {},
   "source": [
    "#### Load Training Dataset and Soil Dataset.  Convert Training Dataset date variable from object to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e920ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local location of the data\n",
    "# local_data = 'D:\\\\Data_Science\\\\DroughtProject\\\\Data\\\\' # Location on Windows\n",
    "local_data = '/home/chad/Data/Drought_Prediction/' # Location on Linux\n",
    "\n",
    "# Load the training set and the soil variables.\n",
    "soil_set = pd.read_csv(local_data + 'soil_data.csv')\n",
    "test_set = pd.read_csv(local_data + 'test_timeseries.csv',\n",
    "                        parse_dates=['date'],\n",
    "                        header=0)\n",
    "val_set = pd.read_csv(local_data + 'validation_timeseries.csv',\n",
    "                        parse_dates=['date'],\n",
    "                        header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6356acdf",
   "metadata": {},
   "source": [
    "#### Confirm datasets are properly loaded and contain expected datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f355f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6951f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5382916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2614ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d7337",
   "metadata": {},
   "source": [
    "## Combine Test & Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a6e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using concat to merge test and validation datasets.\n",
    "testval = pd.concat([val_set, test_set], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da1d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testval.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf97f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "testval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bcc077",
   "metadata": {},
   "source": [
    "### Resample Meteorolgical Variables to weekly variables with non-null Score values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ac8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each county ('fips'), since the score value is set on Tuesday, \n",
    "# all variables are averaged from the week leading up to Tuesday: previous Wednesday to Tuesday.\n",
    "testval_mean = test_set.groupby('fips').resample('W-TUE', on='date').mean()\n",
    "testval_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19728444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Groupby returns a MultiIndex.\n",
    "testval_mean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be74073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'fips' is both part of the MultiIndex and a copied column.\n",
    "#  Need to rename (or delete) before resetting the index.\n",
    "testval_mean.rename({'fips': 'fips_copy'}, axis=1, inplace=True)\n",
    "\n",
    "testval_mean.reset_index(inplace=True)\n",
    "testval_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24af98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming expected column dataypes, overall size, memory usage, etc.\n",
    "testval_mean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98610424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last Score value is NaN.  Filling that value with last valid value.\n",
    "testval_mean.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'fips_copy' is a copy and has been verified as no longer needed.\n",
    "testval_mean.drop('fips_copy', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e934060",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Confirming proper structure and expected output.\n",
    "testval_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6c52da",
   "metadata": {},
   "source": [
    "### Repeat process of resampling but use the max() value instead of mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5904b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each county ('fips'), since the score value is set on Tuesday, \n",
    "# find the max for all variables from the week leading up to Tuesday: previous Wednesday to Tuesday.\n",
    "train_set_max = train_set.groupby('fips').resample('W-TUE', on='date').max()\n",
    "\n",
    "train_set_max.rename({'fips': 'fips_copy', 'date': 'date_copy'}, axis=1, inplace=True)\n",
    "train_set_max.reset_index(inplace=True)\n",
    "train_set_max.fillna(method='ffill', inplace=True)\n",
    "train_set_max.drop(['fips_copy', 'date_copy'], axis=1, inplace=True)\n",
    "\n",
    "train_set_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b907d7",
   "metadata": {},
   "source": [
    "### Repeat process of resampling but use the min() value instead of mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE FUNCTION FOR THIS PROCESS\n",
    "\n",
    "# For each county ('fips'), since the score value is set on Tuesday, \n",
    "# find the max for all variables from the week leading up to Tuesday: previous Wednesday to Tuesday.\n",
    "train_set_min = train_set.groupby('fips').resample('W-TUE', on='date').min()\n",
    "\n",
    "train_set_min.rename({'fips': 'fips_copy', 'date': 'date_copy'}, axis=1, inplace=True)\n",
    "train_set_min.reset_index(inplace=True)\n",
    "train_set_min.fillna(method='ffill', inplace=True)\n",
    "train_set_min.drop(['fips_copy', 'date_copy'], axis=1, inplace=True)\n",
    "\n",
    "train_set_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf3c45e",
   "metadata": {},
   "source": [
    "### Merge Mean, Min, & Max Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add '_mean' suffix so when the tables are joined, the variable suffixes have a standard meaning.\n",
    "train_set_mean = train_set_mean.add_suffix('_mean')\n",
    "train_set_max = train_set_max.add_suffix('_max')\n",
    "train_set_min = train_set_min.add_suffix('_min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fdb7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats_temp = train_set_mean.join(train_set_max, how='inner', rsuffix = '_max')\n",
    "train_stats_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f8482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats =  train_stats_temp.join(train_set_min, how='inner', rsuffix='_min')\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0fb7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Date, FIPS, and Score values don't have min or max values different from mean and are therefore duplicates.\n",
    "train_stats.drop(['fips_max', 'date_max', 'score_max', 'fips_min', 'date_min', 'score_min'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33147e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats.rename({'fips_mean': 'fips', 'date_mean': 'date', 'score_mean':'score'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196da280",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2181951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging the columns so that fips, date, and score are the first three columns.\n",
    "\n",
    "cols = train_stats.columns.tolist()\n",
    "cols = cols[0:2] + [cols[20]] + cols[2:20] + cols[21:]\n",
    "# type(cols)\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17599892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train_stats[cols]\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ca61b",
   "metadata": {},
   "source": [
    "### Directly using Merge to correctly join on specified column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9280ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_soil_stats = pd.merge(train_stats, soil_set, on='fips', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b535ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_soil_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783fb2b4",
   "metadata": {},
   "source": [
    "#### There are the same number of rows in the training set and the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d6aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_soil_stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d9a48",
   "metadata": {},
   "source": [
    "### Exporting the Merged Training and Soil Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa039de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the merged training (meteorological) data that has been resampled with mean values\n",
    "# and the soil data that does not vary with time.\n",
    "train_soil_stats.to_csv(local_data + 'train_soil_stats.csv',\n",
    "                       index_label='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
